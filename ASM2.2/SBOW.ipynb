{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17nMkdmG7w0OebO6RY8IFlDxcukecculj",
      "authorship_tag": "ABX9TyP1Z8vb2CxAlXDPBQIsuUqH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinhDT22022522/NLP-ASM2/blob/main/SBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/word2vec/truyen_kieu_data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n"
      ],
      "metadata": {
        "id": "4pKslIb0O4zh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1tCAwWZ9PJjt",
        "outputId": "5f0db247-efa2-407b-a455-03551eae9e0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1..Trăm năm trong cõi người ta,\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string as pystring\n",
        "\n",
        "# Định nghĩa các ký tự cần loại bỏ\n",
        "PUNCT_TO_REMOVE = pystring.punctuation + pystring.digits + \"\\n\"\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Hàm tùy chỉnh để loại bỏ dấu câu và số\"\"\"\n",
        "    text = text.lower()  # chuyển thành chữ thường\n",
        "    text = text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "    return text\n",
        "\n",
        "# Ví dụ kiểm tra hàm clean_text\n",
        "print(clean_text(lines[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caFY7ZdVPhHY",
        "outputId": "be769224-f093-47f7-aaed-560cf95420df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trăm năm trong cõi người ta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_lines = [clean_text(line) for line in lines]"
      ],
      "metadata": {
        "id": "sFMqAV2DThZX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string as pystring\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Lambda\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "wJowVHwzTQrR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_centers_and_contexts(corpus, max_window_size=2):\n",
        "    centers, contexts = [], []\n",
        "    for line in corpus:\n",
        "        line = line.split()\n",
        "        if len(line) <= 2 * max_window_size:\n",
        "            continue\n",
        "        for i in range(max_window_size, len(line) - max_window_size):\n",
        "            centers.append(line[i])\n",
        "            idxs = list(range(i - max_window_size, i + max_window_size + 1))\n",
        "            idxs.remove(i)\n",
        "            contexts.append(\" \".join([line[idx] for idx in idxs]))\n",
        "    return centers, contexts\n"
      ],
      "metadata": {
        "id": "NPNJCxsjQP__"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centers, contexts = get_centers_and_contexts(cleaned_lines)"
      ],
      "metadata": {
        "id": "Jagm3TU1Q6DW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "embedding_size = 200\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(cleaned_lines)\n",
        "\n",
        "vocab_size = len(tokenizer.index_word) + 1\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(contexts)\n",
        "train_seq_pad = pad_sequences(train_seq, maxlen=max_length, truncating='post', padding='post')\n",
        "\n",
        "train_labels = [to_categorical(tokenizer.word_index[label], vocab_size) for label in centers]\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "U87D-GplROx5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbow = Sequential()\n",
        "cbow.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_length))\n",
        "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embedding_size,)))\n",
        "cbow.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "cbow.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "cbow.summary()\n",
        "\n",
        "cbow.fit(train_seq_pad, train_labels, epochs=30, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udEHfUq8TsBw",
        "outputId": "77eaa4bb-0694-42be-d377-9411fb122635"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 200)            479000    \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 200)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2395)              481395    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 960395 (3.66 MB)\n",
            "Trainable params: 960395 (3.66 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "306/306 [==============================] - 9s 22ms/step - loss: 7.4525 - acc: 0.0183\n",
            "Epoch 2/30\n",
            "306/306 [==============================] - 7s 22ms/step - loss: 6.7268 - acc: 0.0209\n",
            "Epoch 3/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 6.5661 - acc: 0.0249\n",
            "Epoch 4/30\n",
            "306/306 [==============================] - 6s 19ms/step - loss: 6.3914 - acc: 0.0336\n",
            "Epoch 5/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 6.1441 - acc: 0.0542\n",
            "Epoch 6/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 5.8140 - acc: 0.0772\n",
            "Epoch 7/30\n",
            "306/306 [==============================] - 6s 20ms/step - loss: 5.4111 - acc: 0.1118\n",
            "Epoch 8/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 4.9549 - acc: 0.1544\n",
            "Epoch 9/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 4.4676 - acc: 0.2103\n",
            "Epoch 10/30\n",
            "306/306 [==============================] - 6s 20ms/step - loss: 3.9758 - acc: 0.2739\n",
            "Epoch 11/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 3.5011 - acc: 0.3461\n",
            "Epoch 12/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 3.0577 - acc: 0.4224\n",
            "Epoch 13/30\n",
            "306/306 [==============================] - 6s 19ms/step - loss: 2.6544 - acc: 0.4980\n",
            "Epoch 14/30\n",
            "306/306 [==============================] - 5s 15ms/step - loss: 2.2964 - acc: 0.5689\n",
            "Epoch 15/30\n",
            "306/306 [==============================] - 4s 15ms/step - loss: 1.9824 - acc: 0.6311\n",
            "Epoch 16/30\n",
            "306/306 [==============================] - 5s 18ms/step - loss: 1.7097 - acc: 0.6865\n",
            "Epoch 17/30\n",
            "306/306 [==============================] - 5s 17ms/step - loss: 1.4751 - acc: 0.7394\n",
            "Epoch 18/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 1.2747 - acc: 0.7827\n",
            "Epoch 19/30\n",
            "306/306 [==============================] - 5s 17ms/step - loss: 1.1029 - acc: 0.8190\n",
            "Epoch 20/30\n",
            "306/306 [==============================] - 5s 18ms/step - loss: 0.9570 - acc: 0.8509\n",
            "Epoch 21/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 0.8317 - acc: 0.8793\n",
            "Epoch 22/30\n",
            "306/306 [==============================] - 6s 19ms/step - loss: 0.7251 - acc: 0.8984\n",
            "Epoch 23/30\n",
            "306/306 [==============================] - 5s 17ms/step - loss: 0.6334 - acc: 0.9169\n",
            "Epoch 24/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 0.5550 - acc: 0.9300\n",
            "Epoch 25/30\n",
            "306/306 [==============================] - 5s 17ms/step - loss: 0.4874 - acc: 0.9439\n",
            "Epoch 26/30\n",
            "306/306 [==============================] - 6s 18ms/step - loss: 0.4295 - acc: 0.9531\n",
            "Epoch 27/30\n",
            "306/306 [==============================] - 5s 16ms/step - loss: 0.3789 - acc: 0.9607\n",
            "Epoch 28/30\n",
            "306/306 [==============================] - 5s 17ms/step - loss: 0.3349 - acc: 0.9661\n",
            "Epoch 29/30\n",
            "306/306 [==============================] - 6s 18ms/step - loss: 0.2969 - acc: 0.9713\n",
            "Epoch 30/30\n",
            "306/306 [==============================] - 4s 14ms/step - loss: 0.2637 - acc: 0.9768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78018a113820>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = 'trăm năm cõi người'\n",
        "sample_seq = tokenizer.texts_to_sequences([sample_text])\n",
        "sample_seq_pad = pad_sequences(sample_seq, maxlen=max_length, truncating='post', padding='post')\n",
        "predicted_word_idx = np.argmax(cbow.predict(sample_seq_pad))\n",
        "predicted_word = tokenizer.index_word[predicted_word_idx]\n",
        "\n",
        "print(f\"Predicted center word: {predicted_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj0c9jq_TvSO",
        "outputId": "318dfe86-797c-4f91-c1a7-a3274fd9dea4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 179ms/step\n",
            "Predicted center word: trong\n"
          ]
        }
      ]
    }
  ]
}