{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhQfTu40xjvxNfmo0gGAak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinhDT22022522/NLP-ASM2/blob/main/vector_space_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lERAUKA10M7Z",
        "outputId": "661a1e4a-26e7-4273-84e9-f8cd204bacc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7Xwf4D20UCx",
        "outputId": "20d7a8e4-e943-4789-88ba-1404ad324b15"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvi.ViTokenizer import tokenize\n",
        "import re, os, string\n",
        "import pandas as pd\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub('<.*?>', '', text).strip()\n",
        "    text = re.sub('(\\s)+', r'\\1', text)\n",
        "    return text\n",
        "\n",
        "def normalize_text(text):\n",
        "    listpunctuation = string.punctuation.replace('_', '')\n",
        "    for i in listpunctuation:\n",
        "        text = text.replace(i, ' ')\n",
        "    return text.lower()\n",
        "\n",
        "# List stopwords\n",
        "filename = '/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/stopwords.csv'\n",
        "data = pd.read_csv(filename, sep=\"\\t\", encoding='utf-8')\n",
        "list_stopwords = data['stopwords']\n",
        "\n",
        "def remove_stopword(text):\n",
        "    pre_text = []\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        if word not in list_stopwords:\n",
        "            pre_text.append(word)\n",
        "    text2 = ' '.join(pre_text)\n",
        "\n",
        "    return text2\n",
        "\n",
        "def sentence_segment(text):\n",
        "    sents = re.split(\"([.?!])?[\\n]+|[.?!] \", text)\n",
        "    return sents\n",
        "\n",
        "def word_segment(sent):\n",
        "    sent = tokenize(sent)\n",
        "    return sent\n",
        "\n",
        "path_to_corpus = '/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/AA/wiki_00'\n",
        "\n",
        "f_w = open('/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/datatrain.txt', 'w', encoding='utf-8')\n",
        "\n",
        "with open(path_to_corpus, 'r', encoding='utf-8') as f_r:\n",
        "    contents = f_r.read().strip().split('</doc>')\n",
        "    for content in contents:\n",
        "        if len(content) < 5:\n",
        "            continue\n",
        "        content = clean_text(content)\n",
        "        sents = sentence_segment(content)\n",
        "        for sent in sents:\n",
        "            if sent:\n",
        "                sent = word_segment(sent)\n",
        "                sent = remove_stopword(normalize_text(sent))\n",
        "                if len(sent.split()) > 1:\n",
        "                    f_w.write(sent + '\\n')\n",
        "\n",
        "f_w.close()\n"
      ],
      "metadata": {
        "id": "F9pHpbJ83HZv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "\n",
        "# Đường dẫn tới thư mục lưu trữ mô hình\n",
        "model_dir = '/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/model'\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# Đường dẫn tới dữ liệu huấn luyện\n",
        "path_data = '/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/datatrain.txt'\n",
        "\n",
        "def read_data(path):\n",
        "    train_data = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            train_data.append(line.split())\n",
        "    return train_data\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Đọc dữ liệu\n",
        "    train_data = read_data(path_data)\n",
        "\n",
        "    # Huấn luyện mô hình Word2Vec\n",
        "    model_w2v = Word2Vec(sentences=train_data, vector_size=150, window=10, min_count=2, workers=4, sg=0)\n",
        "\n",
        "    # Lưu mô hình Word2Vec đầy đủ\n",
        "    model_file = os.path.join(model_dir, \"word2vec.model\")\n",
        "    try:\n",
        "        model_w2v.save(model_file)\n",
        "        print(f\"Model saved successfully to {model_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o6x7XQL6Xex",
        "outputId": "80b2a1ed-bfec-4386-a469-c139bdb56de2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully to /content/drive/MyDrive/Colab_Notebooks/NLP/Week2/model/word2vec.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "import os\n",
        "\n",
        "# Đường dẫn tới thư mục lưu trữ mô hình\n",
        "model_dir = '/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/model'\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# Đường dẫn tới dữ liệu huấn luyện\n",
        "path_data = '/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/datatrain.txt'\n",
        "\n",
        "def read_data(path):\n",
        "    train_data = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            train_data.append(line.split())\n",
        "    return train_data\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Đọc dữ liệu\n",
        "    train_data = read_data(path_data)\n",
        "\n",
        "    # Huấn luyện mô hình fastText\n",
        "    model_fasttext = FastText(vector_size=150, window=10, min_count=2, workers=4, sg=1)\n",
        "    model_fasttext.build_vocab(corpus_file=path_data)\n",
        "    model_fasttext.train(corpus_file=path_data, total_examples=model_fasttext.corpus_count, total_words=model_fasttext.corpus_total_words, epochs=10)\n",
        "\n",
        "    # Lưu mô hình\n",
        "    model_file = os.path.join(model_dir, \"fasttext.model\")\n",
        "    try:\n",
        "        model_fasttext.save(model_file)\n",
        "        print(f\"Model saved successfully to {model_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xRBQM6a7dqt",
        "outputId": "89b17d22-f651-480b-cb79-d18f63b46762"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully to /content/drive/MyDrive/Colab_Notebooks/NLP/Week2/model/fasttext.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "# Đường dẫn tới mô hình fastText đã lưu\n",
        "model_path = '/content/drive/MyDrive/Colab_Notebooks/NLP/Week2/model/fasttext.model'\n",
        "\n",
        "# Load mô hình\n",
        "model = FastText.load(model_path)\n",
        "\n",
        "# Ví dụ sử dụng mô hình\n",
        "word = 'công_nghệ'\n",
        "similar_words = model.wv.most_similar(word)\n",
        "print(f\"Các từ tương đồng với '{word}':\")\n",
        "for sim_word, sim_score in similar_words:\n",
        "    print(f\"- {sim_word}: {sim_score}\")\n",
        "\n",
        "# Tính độ tương đồng giữa hai từ\n",
        "word1 = 'máy_tính'\n",
        "word2 = 'phần_mềm'\n",
        "similarity = model.wv.similarity(word1, word2)\n",
        "print(f\"Độ tương đồng giữa '{word1}' và '{word2}': {similarity}\")\n",
        "\n",
        "# Nhúng vector của một từ\n",
        "embedding = model.wv[word]\n",
        "print(f\"Vector biểu diễn của '{word}':\")\n",
        "print(embedding)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q38AV9hu8WVF",
        "outputId": "b6cb40de-38dd-4194-cd25-6be1687fdecc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Các từ tương đồng với 'công_nghệ':\n",
            "- công_nghệ_cao: 0.9568533897399902\n",
            "- công_nghiệp: 0.9311946034431458\n",
            "- công_tác: 0.8829225897789001\n",
            "- công_ty_con: 0.8553340435028076\n",
            "- mỏ: 0.8378849625587463\n",
            "- công_ty: 0.8351039886474609\n",
            "- chất_thải: 0.8321520090103149\n",
            "- xây_dựng: 0.8260173797607422\n",
            "- xử_lý: 0.8235334157943726\n",
            "- doanh_nghiệp: 0.8115085959434509\n",
            "Độ tương đồng giữa 'máy_tính' và 'phần_mềm': 0.7191945910453796\n",
            "Vector biểu diễn của 'công_nghệ':\n",
            "[ 0.32453415 -0.407155   -0.11300841  0.0508524  -0.13862889  0.12706842\n",
            "  0.34817088  0.21037945 -0.04579591 -0.15166341 -0.16493711  0.11099705\n",
            " -0.06050544 -0.33607385 -0.12834756 -0.39662936 -0.33456424  0.08054994\n",
            " -0.14553684  0.20931049  0.0598273   0.11640912  0.04737476  0.1145734\n",
            " -0.13153334 -0.14935179 -0.11864572 -0.3588208   0.18707359  0.02021561\n",
            "  0.07351134 -0.3637228   0.3099879  -0.06573392 -0.02734224 -0.05424011\n",
            " -0.17509072 -0.40064347 -0.01571399 -0.29524663  0.06303214  0.06013732\n",
            "  0.12795639  0.39757347  0.12265465  0.03739996 -0.11563399 -0.65190834\n",
            "  0.11314811  0.05105297  0.26186222 -0.03525175 -0.2542106   0.03334072\n",
            " -0.63004136  0.06060992  0.23209059  0.00492566  0.10454501  0.06642313\n",
            " -0.45092064  0.12886353  0.3209769   0.4184161  -0.17809533 -0.43344092\n",
            " -0.10401374 -0.17633401  0.09401856  0.02168077  0.01834566  0.20639713\n",
            "  0.19538866  0.01767461  0.3431791  -0.10989967 -0.30702773 -0.13242042\n",
            "  0.1253913   0.05271345  0.14772755  0.41263032  0.08472542  0.09922671\n",
            " -0.37737185  0.1803744   0.02467505  0.10763462  0.19181547 -0.05360341\n",
            " -0.07318977 -0.4876849  -0.00522419 -0.13624074  0.15792994  0.23628189\n",
            " -0.13342462 -0.17691888 -0.09944541  0.06559674  0.45659325  0.24759318\n",
            " -0.43203598 -0.08745472  0.37807074  0.17759444  0.3455223   0.25709492\n",
            " -0.03046111 -0.08777826 -0.20456468  0.28665638  0.12812619 -0.3337107\n",
            " -0.09930657  0.17378278  0.11322533 -0.09252922 -0.11066262  0.29728806\n",
            "  0.23599769  0.03897366 -0.6898172  -0.0095684  -0.01913372  0.09026217\n",
            "  0.02574161  0.09289714  0.20546934 -0.00398387  0.4455766   0.03562864\n",
            " -0.4198559  -0.515207    0.25215086  0.22401842 -0.15598232 -0.09560173\n",
            " -0.14837904 -0.15390466 -0.2546011   0.11292744  0.13483936 -0.0013901\n",
            " -0.2697451   0.2171962   0.21571428 -0.3361875   0.06046995 -0.24748138]\n"
          ]
        }
      ]
    }
  ]
}